<QueryConfig AutoExecuteQueryOnLoad="false" PreventSQLBeautification="false">
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/30/2019 11:43:49 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/30/2019 11:22:45 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/30/2019 11:19:03 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/30/2019 11:18:36 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/30/2019 9:16:05 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/30/2019 9:15:53 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/29/2019 5:33:18 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/29/2019 5:31:39 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/29/2019 5:28:23 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/29/2019 4:42:11 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/22/2019 1:50:21 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/22/2019 1:49:01 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/22/2019 11:07:28 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/17/2019 5:23:36 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/17/2019 5:20:46 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_kjdejong on 4/17/2019 5:19:36 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.70713.2318</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 9/30/2014 8:55:32 AM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40923.2310</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/12/2013 12:11:00 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.7.31110.0013</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/12/2013 12:10:47 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.7.31110.0013</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 5/1/2013 4:52:18 PM from RF3PTS215.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.6.30430.2016</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 2/4/2013 11:31:35 AM from RF3PTS215.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.6.30204.0928</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 2/4/2013 11:30:30 AM from RF3PTS215.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.6.30204.0928</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 1/30/2013 11:32:01 AM from RF3PTS215.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.6.30129.2054</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 1/30/2013 11:31:44 AM from RF3PTS215.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.6.30129.2054</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 1/30/2013 10:54:57 AM from RF3PTS215.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.6.30129.2054</ChangeLog>
  <UNIQECredentials UserId="uber" Site="rf3sap110-alias.rf3stg.mfgint.intel.com" DataSource="D1D_STAG_LogAnalyzer" SaveCredentials="true" UseUNIQECredentialsOnStartUp="false" QueryTimeOutInSeconds="-1">
    <Password />
    <Name />
  </UNIQECredentials>
  <QueryAttributes>
    <OutputDateFormat>yyyy/MM/dd</OutputDateFormat>
    <PreserveTempFiles>true</PreserveTempFiles>
  </QueryAttributes>
  <PostQuerySQL>select * from %{OUTPUT}</PostQuerySQL>
  <TableLayoutConfig>
    <BoundColumnList>Entity,CE Code,life,Process,Building,Bay,Event Sub Type,SL1Finish,SL1Finish+WW,FinishDate,CapCode</BoundColumnList>
  </TableLayoutConfig>
  <RowHighlightingRules Enable="true" ColumnName="Globals" FilterRegex="O" RowColorString="NamedColor:White" />
  <RowHighlightingRules Enable="true" ColumnName="Platforms" FilterRegex="O" RowColorString="NamedColor:White" />
  <RowHighlightingRules Enable="true" ColumnName="AWIT" FilterRegex="O" RowColorString="NamedColor:White" />
  <RowHighlightingRules Enable="true" ColumnName="Pingable_WC" FilterRegex="Pingable" RowColorString="NamedColor:Lime" />
  <RowHighlightingRules Enable="true" ColumnName="Pingable_WC" FilterRegex="" RowColorString="NamedColor:White" />
  <TabOrder>G0,C0,G1</TabOrder>
  <MainPivotConfig Enable="true">
    <QuerySQL>---[MAIN_CSV]---
BEGIN MAIN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		*
	FROM
		%{output}
END MAIN_CSV
---[ACTUAL_CSV]---
BEGIN ACTUAL_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		FinishWW as WW,
		Count(*) as TotalActual
	FROM
		%{MAIN_CSV}
	WHERE
		capcode like 'WC'
		and FinishDate is not null
		and FinishDate &lt; SUB(TO_LOCALTIME(SYSTEM_TIMESTAMP()), TIMESTAMP( '7', 'd' ) )
	GROUP BY
		WW
	ORDER BY
		WW
END ACTUAL_CSV
---[PLAN_CSV]---
BEGIN PLAN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		SLADueDateWW as WW,
		Count(*) as TotalPlan
	FROM
		%{MAIN_CSV}
	WHERE
		capcode like 'WC'
	GROUP BY
		WW
	ORDER BY
		WW
END PLAN_CSV
---[SL1_CSV]---
BEGIN SL1_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		SL1FinishWW as WW,
		Count(*) as SL1Plan
	FROM
		%{MAIN_CSV}
	WHERE
		capcode like 'WC'
	GROUP BY
		WW
	ORDER BY
		WW
END SL1_CSV
---[SUM_CSV]---
BEGIN SUM_CSV
	UseMethod CalculateRunningSum with -- **Get Running Sum for a Column in the Table**
		InputFile = "%{ACTUAL_CSV}" -- Input CSV file [String]
		ColumnToCalculateSumFor = "TotalActual" -- Input CSV file [String]
		PivotColumn = "" -- Pivot column (optional) [String]
		NewColumnForRunningSum = "Actual" -- New column to be added with running sum [String]
		NewColumnForAbsoluteRunningSum = "AbsoluteRunningTotalActual" -- New column to be added with absolute running sum which ignores the pivot column [String]
END SUM_CSV
---[SUMPLAN_CSV]---
BEGIN SUMPLAN_CSV
	UseMethod CalculateRunningSum with -- **Get Running Sum for a Column in the Table**
		InputFile = "%{PLAN_CSV}" -- Input CSV file [String]
		ColumnToCalculateSumFor = "TotalPlan" -- Input CSV file [String]
		PivotColumn = "" -- Pivot column (optional) [String]
		NewColumnForRunningSum = "Planned" -- New column to be added with running sum [String]
		NewColumnForAbsoluteRunningSum = "AbsoluteRunningPlan" -- New column to be added with absolute running sum which ignores the pivot column [String]
END SUMPLAN_CSV
---[SUMSL1_CSV]---
BEGIN SUMSL1_CSV
	UseMethod CalculateRunningSum with -- **Get Running Sum for a Column in the Table**
		InputFile = "%{SL1_CSV}" -- Input CSV file [String]
		ColumnToCalculateSumFor = "SL1Plan" -- Input CSV file [String]
		PivotColumn = "" -- Pivot column (optional) [String]
		NewColumnForRunningSum = "SL1Planned" -- New column to be added with running sum [String]
		NewColumnForAbsoluteRunningSum = "AbsoluteRunningPlan" -- New column to be added with absolute running sum which ignores the pivot column [String]
END SUMSL1_CSV
---[JOIN_CSV]---
BEGIN JOIN_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{SUM_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{SUMPLAN_CSV}" -- Input CSV File #2 containing table data [String]
		InputFile3 = "%{SUMSL1_CSV}" -- Input CSV File #3 containing table data (optional) [String]
		JoinColumn = "WW" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = false -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
END JOIN_CSV
---Begin Main Query---
Using CSV with
SELECT
	Top 10
	WW,
	Actual,
	Planned,
	SL1Planned
FROM
	%{JOIN_CSV}
ORDER BY
	WW desc
</QuerySQL>
    <ColumnX FieldName="WW" FieldType="String" SortMode="Default" SortOrder="Ascending" SummaryType="Sum" SortBySummaryInfo="false" />
    <ColumnY FieldName="" FieldType="" SortMode="Default" SortOrder="Ascending" SummaryType="Count" SortBySummaryInfo="false" />
    <ColumnData FieldName="Actual, Planned" FieldType="Int32" SortMode="Default" SortOrder="Ascending" SummaryType="Average,Average" SortBySummaryInfo="false" />
    <ChartType>Line</ChartType>
    <Name>WC Installed</Name>
    <ChartTitle>WC Installed
Planned vs. Actual</ChartTitle>
    <ColorPalette>Median</ColorPalette>
    <ChartExportSize>800x400</ChartExportSize>
    <AlwaysShowThresholdLines>true</AlwaysShowThresholdLines>
    <TimeIntervalForDateScale>7d</TimeIntervalForDateScale>
    <DateFormat>Auto</DateFormat>
    <CustomPalette />
    <TableData />
  </MainPivotConfig>
  <OutputDataGridConfig Name="WW">
    <SQL>---[MAIN_CSV]---
BEGIN MAIN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		*
	FROM
		%{output}
END MAIN_CSV
---[ACTUAL_CSV]---
BEGIN ACTUAL_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		FinishWW as WW,
		Count(*) as TotalActual
	FROM
		%{MAIN_CSV}
	WHERE
		capcode like 'WC' and FinishDate is not null
	GROUP BY
		WW
	ORDER BY
		WW
END ACTUAL_CSV
---[PLAN_CSV]---
BEGIN PLAN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		SLADueDateWW as WW,
		Count(*) as TotalPlan
	FROM
		%{MAIN_CSV}
	WHERE
		capcode like 'WC'
	GROUP BY
		WW
	ORDER BY
		WW
END PLAN_CSV
---[SUM_CSV]---
BEGIN SUM_CSV
	UseMethod CalculateRunningSum with -- **Get Running Sum for a Column in the Table**
		InputFile = "%{ACTUAL_CSV}" -- Input CSV file [String]
		ColumnToCalculateSumFor = "TotalActual" -- Input CSV file [String]
		PivotColumn = "" -- Pivot column (optional) [String]
		NewColumnForRunningSum = "Actual" -- New column to be added with running sum [String]
		NewColumnForAbsoluteRunningSum = "AbsoluteRunningTotalActual" -- New column to be added with absolute running sum which ignores the pivot column [String]
END SUM_CSV
---[SUMPLAN_CSV]---
BEGIN SUMPLAN_CSV
	UseMethod CalculateRunningSum with -- **Get Running Sum for a Column in the Table**
		InputFile = "%{PLAN_CSV}" -- Input CSV file [String]
		ColumnToCalculateSumFor = "TotalPlan" -- Input CSV file [String]
		PivotColumn = "" -- Pivot column (optional) [String]
		NewColumnForRunningSum = "Planned" -- New column to be added with running sum [String]
		NewColumnForAbsoluteRunningSum = "AbsoluteRunningPlan" -- New column to be added with absolute running sum which ignores the pivot column [String]
END SUMPLAN_CSV
---[JOIN_CSV]---
BEGIN JOIN_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{SUM_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{SUMPLAN_CSV}" -- Input CSV File #2 containing table data [String]
		JoinColumn = "WW" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = false -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
END JOIN_CSV
---Begin Main Query---
Using CSV with
SELECT
	top 12
	WW,
	Actual,
	Planned
FROM
	%{JOIN_CSV}
ORDER BY
	WW desc
</SQL>
    <TableLayoutConfig>
      <BoundColumnList>WW,Actual,Planned</BoundColumnList>
    </TableLayoutConfig>
    <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="WW" type="xs:string" minOccurs="0" />
              <xs:element name="Actual" type="xs:int" minOccurs="0" />
              <xs:element name="Planned" type="xs:int" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
    <TableData />
  </OutputDataGridConfig>
  <OutputDataGridConfig Name="Details">
    <SQL>---[MAIN_CSV]---
BEGIN MAIN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		*
	FROM
		%{OUTPUT}
END MAIN_CSV
---[LATE_CSV]---
BEGIN LATE_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		SLADueDateWW as WW,
		'Late' as Status,
		Entity as SCCompleted
	FROM
		%{MAIN_CSV}
	WHERE
		CapCode = 'WC' and
		[SLADueDate] &lt; SUB(TO_LOCALTIME(SYSTEM_TIMESTAMP()), TIMESTAMP( '7', 'd' ) )
		and ((FinishDate is null) or ((FinishDate &gt; SLADueDate) and FinishDate &gt; SUB(TO_LOCALTIME(SYSTEM_TIMESTAMP()), TIMESTAMP( '7', 'd' ) )))
	ORDER BY
		Entity
END LATE_CSV
---[LATETRAN_CSV]---
BEGIN LATETRAN_CSV
	UseMethod MergeRows with -- **Merge consecutive rows in a given table based on matching column values**
		InputFiles = "%{LATE_CSV}" -- Input files (comma-separated) containing table data [String]
		MergeKeyColumn = "WW,Status" -- Columns (comma-separated) to use for comparing values between consecutive rows before merging [String]
		ColumnsToMerge = "SCCompleted" -- Columns (comma-separated) whose values will be merged [String]
		LineSeparator = ", " -- Line separator to use when merging consecutive consecutive rows [String]
		MaxRowsToMerge = -1 -- Maximum number of rows to merge [Int32]
		MaxCellSizeInBytes = 100000 -- Maximum size of merged cell in bytes [Int32]
END LATETRAN_CSV
---[EARLY_CSV]---
BEGIN EARLY_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		SLADueDateWW as WW,
		'Early' as Status,
		Entity as SCCompleted
	FROM
		%{MAIN_CSV}
	WHERE
		CapCode = 'WC' and
		FinishDate is not null and
		SLADueDate &gt; SUB(TO_LOCALTIME(SYSTEM_TIMESTAMP()), TIMESTAMP( '7', 'd' ) )
		and not FinishWW = SLADueDateWW
	ORDER BY
		Entity
END EARLY_CSV
---[EARLYTRAN_CSV]---
BEGIN EARLYTRAN_CSV
	UseMethod MergeRows with -- **Merge consecutive rows in a given table based on matching column values**
		InputFiles = "%{EARLY_CSV}" -- Input files (comma-separated) containing table data [String]
		MergeKeyColumn = "WW,Status" -- Columns (comma-separated) to use for comparing values between consecutive rows before merging [String]
		ColumnsToMerge = "SCCompleted" -- Columns (comma-separated) whose values will be merged [String]
		LineSeparator = ", " -- Line separator to use when merging consecutive consecutive rows [String]
		MaxRowsToMerge = -1 -- Maximum number of rows to merge [Int32]
		MaxCellSizeInBytes = 100000 -- Maximum size of merged cell in bytes [Int32]
END EARLYTRAN_CSV
---[JOIN_CSV]---
BEGIN JOIN_CSV
	UseMethod MergeTables with -- **Merge content of two tables by doing an outer join on the column schema (no join done here)**
		InputFile1 = "%{LATETRAN_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{EARLYTRAN_CSV}" -- Input CSV File #2 containing table data [String]
		AutoDetectColumnTypes = false -- Auto-detect column types before merging [Boolean]
END JOIN_CSV
---Begin Main Query---
Using CSV with
SELECT
	*
FROM
	%{JOIN_CSV}
</SQL>
    <TableLayoutConfig>
      <BoundColumnList>Status,SCCompleted</BoundColumnList>
    </TableLayoutConfig>
    <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="WW" type="xs:string" minOccurs="0" />
              <xs:element name="Status" type="xs:string" minOccurs="0" />
              <xs:element name="SCCompleted" type="xs:string" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
    <TableData />
  </OutputDataGridConfig>
  <AutoPivotConfig OutputDateFormat="yyyy ww.w hh tt" />
  <MailConfig>
    <PostProcessingSQL Enable="false" />
    <EmailCondition Enable="false" Operator="&gt;" ThresholdRowCount="0">
      <SQLQuery />
      <RunScriptBeforeEmailing>false</RunScriptBeforeEmailing>
      <Script />
    </EmailCondition>
    <PostProcessingCondition Enable="false" Operator="&gt;" ThresholdRowCount="0">
      <SQLQuery />
      <RunScriptBeforeEmailing>false</RunScriptBeforeEmailing>
    </PostProcessingCondition>
    <CopyCondition Enable="false" Operator="&gt;" ThresholdRowCount="0">
      <SQLQuery />
      <RunScriptBeforeEmailing>false</RunScriptBeforeEmailing>
    </CopyCondition>
    <SMTPServer>smtp.intel.com</SMTPServer>
    <From>LogAnalyzer2@intel.com</From>
    <ReplyTo>@{DASHBOARD_OWNER_ALERT_DIST}</ReplyTo>
    <To />
    <Subject>[${DOMAIN}] TIPR_Metrics</Subject>
    <Body />
    <MailAttachments FileNamingFormat="${SETTINGS}" Excel="false" CSV="false" LAS="false" LAD="false" Exceptions="false" StatusLogs="false" PivotChart="true" ZipAttachments="false" DoNotSendAttachmentsWithEmail="false" IncludeJobStatisticsHeader="false" IncludeQuerySettingsFileHeader="false" IncludeVariableDefinitionHeader="false" IncludeRowCountInSubject="false" />
    <IncludeSQLQueryInBody>false</IncludeSQLQueryInBody>
    <TableInBody Enable="true">
      <SQL />
    </TableInBody>
    <CopyOutputToDirectory>true</CopyOutputToDirectory>
    <OutputDirectory>@{DASHBOARD_WEB_SPOOL}\PCAM\Output</OutputDirectory>
    <IncludeAutoPivotSummary>false</IncludeAutoPivotSummary>
    <IncludeCustomPivotSummary>false</IncludeCustomPivotSummary>
    <IgnoreExceptions>false</IgnoreExceptions>
    <OnlyCopyOutputIfEmailConditionIsMet>false</OnlyCopyOutputIfEmailConditionIsMet>
  </MailConfig>
  <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="Entity" type="xs:string" minOccurs="0" />
              <xs:element name="CE_x0020_Code" type="xs:string" minOccurs="0" />
              <xs:element name="life" type="xs:int" minOccurs="0" />
              <xs:element name="Process" type="xs:string" minOccurs="0" />
              <xs:element name="Building" type="xs:string" minOccurs="0" />
              <xs:element name="Bay" type="xs:string" minOccurs="0" />
              <xs:element name="Event_x0020_Sub_x0020_Type" type="xs:string" minOccurs="0" />
              <xs:element name="SL1Finish" type="xs:dateTime" minOccurs="0" />
              <xs:element name="FinishDate" type="xs:dateTime" minOccurs="0" />
              <xs:element name="CapCode" type="xs:string" minOccurs="0" />
              <xs:element name="GlobalsFinishDate" type="xs:dateTime" minOccurs="0" />
              <xs:element name="GlobalsCapCode" type="xs:string" minOccurs="0" />
              <xs:element name="Status" type="xs:string" minOccurs="0" />
              <xs:element name="SL1FinishWW" type="xs:string" minOccurs="0" />
              <xs:element name="FinishWW" type="xs:string" minOccurs="0" />
              <xs:element name="SL1Finish_x002B_WW" type="xs:dateTime" minOccurs="0" />
              <xs:element name="SLADueDate" type="xs:dateTime" minOccurs="0" />
              <xs:element name="SLADueDateWW" type="xs:string" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
  <TableData />
  <LastRunAbsoluteDateFilter />
  <CustomQueryMethodScripts>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.IO;
using System.Text;
using System.Diagnostics;
using System.Text.RegularExpressions;
using Intel.LogAnalyzer;
using Intel.LogAnalyzer.Common;
using Intel.LogAnalyzer.Configuration;
using Intel.LogAnalyzer.Utility;

namespace Intel.LogAnalyzer.BuiltInQueryMethods_Sample
{
    public class CalculateRunningSum : CustomQueryMethodBase
    {

        /// &lt;summary&gt;
        /// Test harness
        /// &lt;/summary&gt;
        [STAThread]
        private static void Main()
        {
            new CalculateRunningSum
            {
                InputFile = @"D:\Temp\test.csv",
                ColumnToCalculateSumFor = "Total",
                PivotColumn = "MetSLA",
                NewColumnForRunningSum = "RunningTotal",
                NewColumnForAbsoluteRunningSum = "AbsoluteRunningTotal"
            }.Test();
        }

        // Output type is QueryResult
        public override CustomQueryOutputType OutputType { get { return CustomQueryOutputType.QueryResult; } }

        public override string Description
        {
            get { return "Get Running Sum for a Column in the Table"; }
        }

        [Description("Input CSV file")]
        public string InputFile { get; set; }
        
        [Description("Input CSV file")]
        public string ColumnToCalculateSumFor { get; set; }
        
        [Description("Pivot column (optional)")]
        [DefaultValue("")]
        public string PivotColumn { get; set; }

        [Description("New column to be added with running sum")]
        [DefaultValue("RunningSum")]
        public string NewColumnForRunningSum { get; set; }
        
        [Description("New column to be added with absolute running sum which ignores the pivot column")]
        [DefaultValue("")]
        public string NewColumnForAbsoluteRunningSum { get; set; }

        public override QueryResult GetQueryResult()
        {
            DataTable table = UtilityMethods.ConvertCSVFileToDataTable(InputFile, true);
            int colIndex = GetColumnIndex(table, ColumnToCalculateSumFor, true);
            int pivotIndex = -1;

            if (PivotColumn.Trim().Length &gt; 0)
            {
                pivotIndex = GetColumnIndex(table, PivotColumn, true);
            }

            table.Columns.Add(NewColumnForRunningSum, typeof(double));
            int newColIndex = GetColumnIndex(table, NewColumnForRunningSum);

            NewColumnForAbsoluteRunningSum = NewColumnForAbsoluteRunningSum.Trim();
            int newAbsColIndex = -1;
            if (NewColumnForAbsoluteRunningSum.Length &gt; 0)
            {
                table.Columns.Add(NewColumnForAbsoluteRunningSum, typeof(double));
                newAbsColIndex = GetColumnIndex(table, NewColumnForAbsoluteRunningSum);
            }

            Dictionary&lt;string, double&gt; dict = new Dictionary&lt;string, double&gt;();
            double absoluteSum = 0.0;

            foreach (DataRow row in table.Rows)
            {
                string key = string.Empty;
                if (pivotIndex &gt;= 0)
                {
                    key = row[pivotIndex].ToStringEx();
                }
                double value = Convert.ToDouble(row[colIndex]);
                absoluteSum += value;
                double sum;
                if (dict.TryGetValue(key, out sum))
                {
                    sum += value;
                    dict[key] = sum;
                }
                else
                {
                    sum = value;
                    dict.Add(key, sum);
                }
                row[newColIndex] = sum;
                if (newAbsColIndex &gt;= 0)
                {
                    row[newAbsColIndex] = absoluteSum;
                }
            }
           
            return new QueryResult(table);
        }

    }
}</CustomQueryMethodScripts>
  <PivotGroupingSettings Enable="true" PivotColumn="IQ_WS">
    <SortyByColumn>Count</SortyByColumn>
  </PivotGroupingSettings>
  <QuerySQL><![CDATA[
--[FileName:"D:\Dashboard\Jobs\PCAM\1-hr\TIPR_Metrics_WC.lasx"]------
----------<VARIABLES>------------
var NODEFILTER = "*"
var DOMAIN = "RF3PROD"
var TIMEFILTER = ""
var SQL_NODE = "@{TIPRSQLNODE}"
var TIPRPW = "@{TIPRPW}"
var TIPRID = "@{TIPRID}"
var CATALOG = "DSI"
var ISSUE_OWNER = "Globals,Platforms,Tool Owners"
---[OLEDB_CSV]---
BEGIN OLEDB_CSV
	---Begin Main Query---
	Using SQLDB with
		HostName = "${SQL_NODE}" -- SQL host name to connect to
		Database = "${CATALOG}" -- Database/catalog name
		UserID = "${TIPRID}" -- User ID to use for connection (leave blank or specify / for IWA)
		Password = "${TIPRPW}" -- Password corresponding to the UserID
	SELECT DISTINCT c.Entity,
		p.[CE Code],
		p.life,
		p.Process,
		p.Building,
		p.Bay,
		p.[Event Sub Type],
		p.[SL1 Finish] AS SL1Finish,
		c.FinishDate,
		c.CapCode
	FROM dbo.EntityCapabilities AS c
	INNER JOIN dbo.Primavera AS p ON (
			c.Entity = p.[Entity Code]
			AND c.Life = p.Life
			)
		AND IsInList(CapCode, 'WC,WStn')
	WHERE p.[SL1 Finish] < getdate() + 30
		AND p.[SL1 Finish] > getdate() - 365
		AND (p.[Event Sub Type] LIKE 'Install%')
	ORDER BY p.[SL1 Finish]
END OLEDB_CSV
---[ISSUES_CSV]---
BEGIN ISSUES_CSV
	---Begin Main Query---
	Using SQLDB with
		HostName = "${SQL_NODE}" -- SQL host name to connect to
		Database = "${CATALOG}" -- Database/catalog name
		UserID = "${TIPRID}" -- User ID to use for connection (leave blank or specify / for IWA)
		Password = "${TIPRPW}" -- Password corresponding to the UserID
	SELECT DISTINCT
	  Entity,
	  Status
	FROM
	  dbo.SetupIssues
	WHERE
	  STATUS = 'Open'
	  AND Isinlist(OWNER, '${ISSUE_OWNER}')
	ORDER  BY
	  Entity 
END ISSUES_CSV
---[AWIT_CSV]---
BEGIN AWIT_CSV
	---Begin Main Query---
	SELECT
		*
	FROM
		%{OLEDB_CSV}
	WHERE
		CapCode = 'WC'
END AWIT_CSV
---[GLOBALS_CSV]---
BEGIN GLOBALS_CSV
	---Begin Main Query---
	SELECT
		Entity,
		life,
		FinishDate as GlobalsFinishDate,
		CapCode as GlobalsCapCode
	FROM
		%{OLEDB_CSV}
	WHERE
		CapCode = 'WStn'
END GLOBALS_CSV
---[JOINGLOBALS_CSV]---
BEGIN JOINGLOBALS_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{AWIT_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{GLOBALS_CSV}" -- Input CSV File #2 containing table data [String]
		JoinColumn = "Entity,life" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = true -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
END JOINGLOBALS_CSV
---[JOINISSUES_CSV]---
BEGIN JOINISSUES_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{JOINGLOBALS_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{ISSUES_CSV}" -- Input CSV File #2 containing table data [String]
		JoinColumn = "Entity" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = true -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
END JOINISSUES_CSV
---Begin Main Query---
Using CSV with
SELECT
	*,
	SL1FinishWW,
	FinishWW,
	[SL1Finish+WW],
	SLADueDate,
	SLADueDateWW
USING
	to_la2date(SL1Finish,'yyyy.ww') as SL1FinishWW,
	to_la2date(FinishDate,'yyyy.ww') as FinishWW,
	add(SL1Finish, TIMESTAMP('0000-01-08', 'yyyy-MM-dd') ) as [SL1Finish+WW],
	to_real(SUB(GlobalsFinishDate, SL1Finish)) as DateDifference,
	case index_of(to_string(DateDifference),'-') when null then GlobalsFinishDate else SL1Finish end as SLADueDate,
	to_la2date(SLADueDate,'yyyy.ww') as SLADueDateWW
FROM
	%{JOINISSUES_CSV}
WHERE
	not GlobalsFinishDate is null
	and (not FinishDate is null
	or (FinishDate is null and Status is null))

]]></QuerySQL>
</QueryConfig>