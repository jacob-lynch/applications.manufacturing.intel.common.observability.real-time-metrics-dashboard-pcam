<QueryConfig AutoExecuteQueryOnLoad="false" PreventSQLBeautification="false">
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/20/2016 1:15:23 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 4:15:34 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 4:10:59 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 4:10:14 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 4:07:57 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 3:56:11 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 3:55:56 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 12/19/2016 3:52:09 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/17/2016 2:48:48 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/17/2016 2:48:14 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/10/2016 11:58:25 AM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/8/2016 2:36:56 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/8/2016 2:36:33 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/8/2016 2:36:19 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/8/2016 2:28:34 PM from RF3PVAP416N19.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.9.60808.1615</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/10/2014 1:29:29 PM from RF3PAP216N2.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40713.1943</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/6/2014 9:43:54 AM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40923.2310</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/5/2014 2:08:30 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40923.2310</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 11/5/2014 12:07:08 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40923.2310</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 8/26/2014 12:32:11 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40806.2215</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 8/26/2014 12:31:40 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40806.2215</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 8/26/2014 12:31:35 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40806.2215</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 8/26/2014 12:10:11 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40806.2215</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 8/26/2014 12:01:10 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40806.2215</ChangeLog>
  <ChangeLog>Changed by AMR\mfg_dmdavies on 8/26/2014 12:00:33 PM from RF3PTS216.RF3PROD.MFG.INTEL.COM using LogAnalyzer2 v2.8.40806.2215</ChangeLog>
  <QueryAttributes>
    <RowThresholdForPivotGrid>1000000</RowThresholdForPivotGrid>
    <AlwaysReplaceDomainWithLocal>false</AlwaysReplaceDomainWithLocal>
  </QueryAttributes>
  <PostQuerySQL>select * from %{OUTPUT}</PostQuerySQL>
  <TableLayoutConfig>
    <BoundColumnList>DateTime,NodeName,EventLog,EventID,EventTypeName,Category,SourceName,UserID,Message,Strings</BoundColumnList>
  </TableLayoutConfig>
  <RowHighlightingRules Enable="true" ColumnName="*" FilterRegex="Error" RowColorString="NamedColor:Red" />
  <RowHighlightingRules Enable="true" ColumnName="*" FilterRegex="Warning" RowColorString="NamedColor:Yellow" />
  <TabOrder>C0,G0,G1,G2</TabOrder>
  <MainPivotConfig>
    <ColumnX FieldName="" FieldType="" SortMode="Default" SortOrder="Ascending" SummaryType="Count" SortBySummaryInfo="false" />
    <ColumnY FieldName="" FieldType="" SortMode="Default" SortOrder="Ascending" SummaryType="Count" SortBySummaryInfo="false" />
    <ColumnData FieldName="" FieldType="" SortMode="Default" SortOrder="Ascending" SummaryType="Count" SortBySummaryInfo="false" />
    <CustomPalette />
    <TableData />
  </MainPivotConfig>
  <OutputDataGridConfig Name="LP" IncludeInBody="false" IncludeInAttachment="true">
    <SQL>---[MAIN_CSV]---
BEGIN MAIN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		DISTINCT
		Operation,
		Process,
		LineSegment,
		PurgeOnLoadPort
	FROM
		%{OUTPUT}
	WHERE
		Enable = 'Y'
		AND State = 'Active'
END MAIN_CSV
---[POL_CSV]---
BEGIN POL_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Process,
		COUNT(*) as PurgeOnLoadPortTotal
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{MAIN_CSV}
	WHERE
		PurgeOnLoadPort = 'Y'
	GROUP BY
		Process
	ORDER BY
		Process
END POL_CSV
---[POLFE_CSV]---
BEGIN POLFE_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Process,
		COUNT(*) as PurgeOnLoadPortFE
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{MAIN_CSV}
	WHERE
		PurgeOnLoadPort = 'Y'
		and LineSegment = 'FE'
	GROUP BY
		Process
	ORDER BY
		Process
END POLFE_CSV
---[POLBE_CSV]---
BEGIN POLBE_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Process,
		COUNT(*) as PurgeOnLoadPortBE
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{MAIN_CSV}
	WHERE
		PurgeOnLoadPort = 'Y'
		and LineSegment = 'BE'
	GROUP BY
		Process
	ORDER BY
		Process
END POLBE_CSV
---[OPER_CSV]---
BEGIN OPER_CSV
	---Begin Main Query---
	Using UNIQE with
		DataSource = "${DATA_SOURCE}" -- UNIQE data source to query
		Authentication = "UNP" -- User Authentication Mode
		UserId = "${MAO_USERID}" -- User ID for authentication
	SELECT
	  OPERATION,
	  CU_FLAG,
	  STATE,
	  DOTPROCESS
	FROM
	  F_OPERATION
	WHERE
	  LATEST_VERSION = 'Y'
	  AND SRC_ERASE_DATE IS NULL 
END OPER_CSV
---[OPERTEMP_CSV]---
BEGIN OPERTEMP_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Process,
		Count(*) as [Total Operations]
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{OPER_CSV}
	WHERE
		NOT IsInList(to_string(Process), '${PURGE_EXCLUDE_PROCESS}')
	GROUP BY
		Process
END OPERTEMP_CSV
---[JOIN_CSV]---
BEGIN JOIN_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{POL_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{POLFE_CSV}" -- Input CSV File #2 containing table data [String]
		InputFile3 = "%{POLBE_CSV}" -- Input CSV File #3 containing table data (optional) [String]
		InputFile4 = "%{OPERTEMP_CSV}" -- Input CSV File #4 containing table data (optional) [String]
		JoinColumn = "Process" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = true -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
		OrderBy = "" -- Name of column(s) to sort the resulting table by [String]
END JOIN_CSV
---Begin Main Query---
Using CSV with
SELECT
	Process,
	[FE Operations],
	[BE Operations],
	PurgeOnLoadPortTotal as [Total PurgeOnLoadPort Enabled Operations],
	[Total Operations]
USING
	CASE to_string(PurgeOnLoadPortFE) when null then '0' else to_string(PurgeOnLoadPortFE) end as [FE Operations],
	CASE to_string(PurgeOnLoadPortBE) when null then '0' else to_string(PurgeOnLoadPortBE) end as [BE Operations]
FROM
	%{JOIN_CSV}
WHERE
	NOT IsInList(to_string(Process), '${PURGE_EXCLUDE_PROCESS}')
</SQL>
    <TableLayoutConfig>
      <BoundColumnList>Enable,Operation,Operation2,Oper3,Route,PurgeOnLoadPort,PurgeInStocker,Coefficient,OperShortDescription,Comment,Process</BoundColumnList>
    </TableLayoutConfig>
    <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="Process" type="xs:string" minOccurs="0" />
              <xs:element name="FE_x0020_Operations" type="xs:int" minOccurs="0" />
              <xs:element name="BE_x0020_Operations" type="xs:int" minOccurs="0" />
              <xs:element name="Total_x0020_PurgeOnLoadPort_x0020_Enabled_x0020_Operations" type="xs:int" minOccurs="0" />
              <xs:element name="Total_x0020_Operations" type="xs:int" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
    <TableData />
  </OutputDataGridConfig>
  <OutputDataGridConfig Name="Stocker" IncludeInBody="false" IncludeInAttachment="true">
    <SQL>---[MAIN_CSV]---
BEGIN MAIN_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		DISTINCT
		Enable,
		Operation,
		Process,
		LineSegment,
		PurgeInStocker
	FROM
		%{OUTPUT}
	WHERE
		Enable = 'Y'
		AND State = 'Active'
END MAIN_CSV
---[PIS_CSV]---
BEGIN PIS_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		DISTINCT
		Process,
		COUNT(*) as PurgeInStockerTotal
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{MAIN_CSV}
	WHERE
		PurgeInStocker = 'Y'
	GROUP BY
		Process
	ORDER BY
		Process
END PIS_CSV
---[PISFE_CSV]---
BEGIN PISFE_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		DISTINCT
		Process,
		COUNT(*) as PurgeInStockerFE
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{MAIN_CSV}
	WHERE
		PurgeInStocker = 'Y'
		and LineSegment = 'FE'
	GROUP BY
		Process
	ORDER BY
		Process
END PISFE_CSV
---[PISBE_CSV]---
BEGIN PISBE_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Process,
		COUNT(*) as PurgeInStockerBE
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{MAIN_CSV}
	WHERE
		PurgeInStocker = 'Y'
		and LineSegment = 'BE'
	GROUP BY
		Process
	ORDER BY
		Process
END PISBE_CSV
---[OPER_CSV]---
BEGIN OPER_CSV
	---Begin Main Query---
	Using UNIQE with
		DataSource = "${DATA_SOURCE}" -- UNIQE data source to query
		Authentication = "UNP" -- User Authentication Mode
		UserId = "${MAO_USERID}" -- User ID for authentication
	SELECT
	  OPERATION,
	  CU_FLAG,
	  STATE,
	  DOTPROCESS
	FROM
	  F_OPERATION
	WHERE
	  LATEST_VERSION = 'Y'
	  AND SRC_ERASE_DATE IS NULL 
END OPER_CSV
---[OPERTEMP_CSV]---
BEGIN OPERTEMP_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Process,
		Count(*) as [Total Operations]
	USING
		CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
		REPLACE_STR(ProcTmp, 'TW', '.0') as Process
	FROM
		%{OPER_CSV}
	WHERE
		NOT IsInList(to_string(Process), '${PURGE_EXCLUDE_PROCESS}')
	GROUP BY
		Process
END OPERTEMP_CSV
---[JOIN_CSV]---
BEGIN JOIN_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{PIS_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{PISFE_CSV}" -- Input CSV File #2 containing table data [String]
		InputFile3 = "%{PISBE_CSV}" -- Input CSV File #3 containing table data (optional) [String]
		InputFile4 = "%{OPERTEMP_CSV}" -- Input CSV File #4 containing table data (optional) [String]
		JoinColumn = "Process" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = true -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
		OrderBy = "" -- Name of column(s) to sort the resulting table by [String]
END JOIN_CSV
---Begin Main Query---
Using CSV with
SELECT
	Process,
	[FE Operations],
	[BE Operations],
	PurgeInStockerTotal as [Total PurgeInStocker Enabled Operations],
	[Total Operations]
USING
	CASE to_string(PurgeInStockerFE) when null then '0' else to_string(PurgeInStockerFE) end as [FE Operations],
	CASE to_string(PurgeInStockerBE) when null then '0' else to_string(PurgeInStockerBE) end as [BE Operations]
FROM
	%{JOIN_CSV}
WHERE
	NOT IsInList(to_string(Process), '${PURGE_EXCLUDE_PROCESS}')
</SQL>
    <TableLayoutConfig>
      <BoundColumnList>Enable,Operation,Operation2,Oper3,Route,PurgeOnLoadPort,PurgeInStocker,Coefficient,OperShortDescription,Comment,Process</BoundColumnList>
    </TableLayoutConfig>
    <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="Process" type="xs:double" minOccurs="0" />
              <xs:element name="FE_x0020_Operations" type="xs:int" minOccurs="0" />
              <xs:element name="BE_x0020_Operations" type="xs:int" minOccurs="0" />
              <xs:element name="Total_x0020_PurgeInStocker_x0020_Enabled_x0020_Operations" type="xs:int" minOccurs="0" />
              <xs:element name="Total_x0020_Operations" type="xs:int" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
    <TableData />
  </OutputDataGridConfig>
  <OutputDataGridConfig Name="DISTINCT" IncludeInBody="false" IncludeInAttachment="true">
    <SQL>---Begin Main Query---
SELECT
	DISTINCT
	Enable,
	Operation,
	PurgeOnLoadPort,
	PurgeInStocker
FROM
	%{OUTPUT}
WHERE
	Enable = 'Y'
	AND State = 'Active'
	AND NOT IsInList(Process, '${PURGE_EXCLUDE_PROCESS}')
</SQL>
    <TableLayoutConfig>
      <BoundColumnList>Enable,Operation,PurgeOnLoadPort,PurgeInStocker</BoundColumnList>
      <AllColumns>Enable</AllColumns>
      <AllColumns>Operation</AllColumns>
      <AllColumns>PurgeOnLoadPort</AllColumns>
      <AllColumns>PurgeInStocker</AllColumns>
    </TableLayoutConfig>
    <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="Enable" type="xs:string" minOccurs="0" />
              <xs:element name="Operation" type="xs:int" minOccurs="0" />
              <xs:element name="PurgeOnLoadPort" type="xs:string" minOccurs="0" />
              <xs:element name="PurgeInStocker" type="xs:string" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
    <TableData />
  </OutputDataGridConfig>
  <AutoPivotConfig OutputDateFormat="yyyy ww.w HH:mm" StatisticalFunctionsForColumn="Avg, 50, 90,96, Count" />
  <MailConfig>
    <PostProcessingSQL Enable="false" />
    <EmailCondition Enable="false" Operator="&gt;=" ThresholdRowCount="0">
      <SQLQuery />
      <RunScriptBeforeEmailing>false</RunScriptBeforeEmailing>
      <Script />
    </EmailCondition>
    <PostProcessingCondition Enable="false" Operator="&gt;" ThresholdRowCount="0">
      <SQLQuery />
      <RunScriptBeforeEmailing>false</RunScriptBeforeEmailing>
    </PostProcessingCondition>
    <CopyCondition Enable="false" Operator="&gt;" ThresholdRowCount="">
      <SQLQuery />
      <RunScriptBeforeEmailing>false</RunScriptBeforeEmailing>
    </CopyCondition>
    <SMTPServer>smtp.intel.com</SMTPServer>
    <From>LogAnalyzer2@intel.com</From>
    <ReplyTo>@{DASHBOARD_OWNER_ALERT_DIST}</ReplyTo>
    <To />
    <Subject>Purge Query XEUS</Subject>
    <Body />
    <MailAttachments FileNamingFormat="${SETTINGS}" Excel="true" LAS="false" LAD="false" Exceptions="false" StatusLogs="false" PivotChart="true" ZipAttachments="false" DoNotSendAttachmentsWithEmail="false" IncludeJobStatisticsHeader="false" IncludeQuerySettingsFileHeader="false" IncludeVariableDefinitionHeader="false" IncludeRowCountInSubject="false" />
    <IncludeSQLQueryInBody>false</IncludeSQLQueryInBody>
    <TableInBody Enable="false">
      <SQL />
    </TableInBody>
    <CopyOutputToDirectory>true</CopyOutputToDirectory>
    <OutputDirectory>@{DASHBOARD_WEB_SPOOL}\PCAM\Output</OutputDirectory>
    <IncludeAutoPivotSummary>false</IncludeAutoPivotSummary>
    <IgnoreExceptions>false</IgnoreExceptions>
    <OnlyCopyOutputIfEmailConditionIsMet>false</OnlyCopyOutputIfEmailConditionIsMet>
  </MailConfig>
  <TableSchema><xs:schema id="NewDataSet" xmlns="" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
  <xs:element name="NewDataSet" msdata:IsDataSet="true" msdata:MainDataTable="Results" msdata:UseCurrentLocale="true">
    <xs:complexType>
      <xs:choice minOccurs="0" maxOccurs="unbounded">
        <xs:element name="Results">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="Enable" type="xs:string" minOccurs="0" />
              <xs:element name="State" type="xs:string" minOccurs="0" />
              <xs:element name="Operation" type="xs:int" minOccurs="0" />
              <xs:element name="Process" type="xs:string" minOccurs="0" />
              <xs:element name="LineSegment" type="xs:string" minOccurs="0" />
              <xs:element name="Route" type="xs:string" minOccurs="0" />
              <xs:element name="PurgeOnLoadPort" type="xs:string" minOccurs="0" />
              <xs:element name="PurgeInStocker" type="xs:string" minOccurs="0" />
              <xs:element name="Coefficient" type="xs:string" minOccurs="0" />
              <xs:element name="OperShortDescription" type="xs:string" minOccurs="0" />
              <xs:element name="Associated_x0020_Entities_x0020_with_x0020_Purge_x0020_Enabled" type="xs:string" minOccurs="0" />
              <xs:element name="Associated_x0020_Entities_x0020_with_x0020_Purge_x0020_Disabled_x0020_or_x0020_Status_x0020_Unknown" type="xs:string" minOccurs="0" />
              <xs:element name="Comment" type="xs:string" minOccurs="0" />
            </xs:sequence>
          </xs:complexType>
        </xs:element>
      </xs:choice>
    </xs:complexType>
  </xs:element>
</xs:schema>
</TableSchema>
  <TableData />
  <LastRunAbsoluteDateFilter />
  <PivotGroupingSettings PivotColumn="">
    <SortyByColumn>Count</SortyByColumn>
  </PivotGroupingSettings>
  <QuerySQL><![CDATA[
--[FileName:"D:\Dashboard\Jobs\PCAM\6-hr\Purge_CRM_Configuration_XEUS.lasx"]------
----------<VARIABLES>------------
var MAO_USERID = "@{USERID_NON_MFG}"
var DATA_SOURCE = "@{LOCALXEUSDATASOURCE}"
var FILEFILTER = "@{DASHBOARD_PERSIST_DATA}\PCAM\Output\1_NTSC_Capability_Summary_DataPull.csv"
var FILEFILTER2 = "@{DASHBOARD_PERSIST_DATA}\PCAM\Output\01_SCDOTNET_Capability_Summary_DataPull.csv"
var PURGE_EXCLUDE_PROCESS = "@{PURGE_EXCLUDE_PROCESS}"
---[OWD_CSV]---
BEGIN OWD_CSV
	---Begin Main Query---
	Using UNIQE with
		DataSource = "${DATA_SOURCE}" -- UNIQE data source to query
		Authentication = "UNP" -- User Authentication Mode
		UserId = "${MAO_USERID}" -- User ID for authentication
	SELECT
	  ENTRY_ROW_ID,
	  ATTRIBUTE_NAME,
	  ATTRIBUTE_DATA
	FROM
	  F_GENERALRELATIONDATA
	WHERE
	  RELATION_NAME = 'PurgeOperationConfigEx'
	  AND SRC_ERASE_DATE IS NULL
	ORDER  BY
	  ENTRY_ROW_ID,
	  ATTRIBUTE_NAME,
	  ATTRIBUTE_DATA 
END OWD_CSV
---[TRANS_CSV]---
BEGIN TRANS_CSV
	UseMethod TransformRowsToColumn with -- **Transforms multiple table rows into new name/value columns**
		InputFile = "%{OWD_CSV}" -- Input CSV file containing table data [String]
		ColumnNameForCaption = "ATTRIBUTE_NAME" -- Caption for new column type created after transformation [String]
		ColumnNameForValue = "ATTRIBUTE_DATA" -- Caption for new column value created after transformation [String]
		ExcludeColumnFilter = "" -- Columns to be excluded from output table (can include wild-cards and be separated by commas) [String]
		DefaultValue = "" -- Default value for cell if one does not exist [String]
END TRANS_CSV
---[ENTITY_CSV]---
BEGIN ENTITY_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		NodeName,
		Name,
		Value
	FROM
		${FILEFILTER}
	WHERE
		(NAME = 'Entity' OR NAME = 'Purge_Enabled')
END ENTITY_CSV
---[DOTNETENTITY_CSV]---
BEGIN DOTNETENTITY_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		NodeName,
		Name,
		Value
	FROM
		${FILEFILTER2}
	WHERE
		(NAME = 'Entity' OR NAME = 'Purge_Enabled')
END DOTNETENTITY_CSV
---[ENTITYTRANS_CSV]---
BEGIN ENTITYTRANS_CSV
	UseMethod TransformRowsToColumn with -- **Transforms multiple table rows into new name/value columns**
		InputFile = "%{ENTITY_CSV}" -- Input CSV file containing table data [String]
		ColumnNameForCaption = "NAME" -- Caption for new column type created after transformation [String]
		ColumnNameForValue = "VALUE" -- Caption for new column value created after transformation [String]
		ExcludeColumnFilter = "" -- Columns to be excluded from output table (can include wild-cards and be separated by commas) [String]
		DefaultValue = "" -- Default value for cell if one does not exist [String]
END ENTITYTRANS_CSV
---[ENTITYTRANS2_CSV]---
BEGIN ENTITYTRANS2_CSV
	UseMethod TransformRowsToColumn with -- **Transforms multiple table rows into new name/value columns**
		InputFile = "%{DOTNETENTITY_CSV}" -- Input CSV file containing table data [String]
		ColumnNameForCaption = "NAME" -- Caption for new column type created after transformation [String]
		ColumnNameForValue = "VALUE" -- Caption for new column value created after transformation [String]
		ExcludeColumnFilter = "" -- Columns to be excluded from output table (can include wild-cards and be separated by commas) [String]
		DefaultValue = "" -- Default value for cell if one does not exist [String]
END ENTITYTRANS2_CSV
---[OPER_CSV]---
BEGIN OPER_CSV
	---Begin Main Query---
	Using UNIQE with
		DataSource = "${DATA_SOURCE}" -- UNIQE data source to query
	SELECT
	  m.ENTITY,
	  op.OPERATION
	FROM
	  F_ENTITY m
	  LEFT OUTER JOIN F_EntityOper op
		ON ( m.ENTITY = op.ENTITY )
	WHERE
	  op.LATEST_FLAG = 'Y'
	  AND m.ENTITY_DELETED_FLAG != 'Y'
	  AND m.STATE != 'Bagged'
	ORDER  BY
	  op.OPERATION,
	  m.ENTITY 
END OPER_CSV
---[SUBFILTER_CSV]---
BEGIN SUBFILTER_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Operation,
		Entity,
		SUBENTITY
	USING
		CASE index_of(ENTITY, '_') when NULL then 'No' else 'Yes' end as SUBENTITY
	FROM
		%{OPER_CSV}
	WHERE
		SUBENTITY = 'No'
END SUBFILTER_CSV
---[MERGESC_CSV]---
BEGIN MERGESC_CSV
	UseMethod MergeTables with -- **Merge content of two tables by doing an outer join on the column schema (no join done here)**
		InputFile1 = "%{ENTITYTRANS_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{ENTITYTRANS2_CSV}" -- Input CSV File #2 containing table data [String]
		AutoDetectColumnTypes = false -- Auto-detect column types before merging [Boolean]
END MERGESC_CSV
---[JOIN_CSV]---
BEGIN JOIN_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{SUBFILTER_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{MERGESC_CSV}" -- Input CSV File #2 containing table data [String]
		JoinColumn = "Entity" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = true -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
		OrderBy = "" -- Name of column(s) to sort the resulting table by [String]
END JOIN_CSV
---[PRE_CSV]---
BEGIN PRE_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Operation,
		Entity,
		Purge
	USING
		CASE PURGE_ENABLED when NULL then 'Associated Entities with Purge Disabled or Status Unknown' when 'No' then 'Associated Entities with Purge Disabled or Status Unknown' else 'Associated Entities with Purge Enabled' end as Purge
	FROM
		%{JOIN_CSV}
	ORDER BY
		OPERATION, Purge, Entity
END PRE_CSV
---[MERGE_CSV]---
BEGIN MERGE_CSV
	UseMethod MergeRows with -- **Merge consecutive rows in a given table based on matching column values**
		InputFiles = "%{PRE_CSV}" -- Input files (comma-separated) containing table data [String]
		MergeKeyColumn = "OPERATION, Purge" -- Columns (comma-separated) to use for comparing values between consecutive rows before merging [String]
		ColumnsToMerge = "ENTITY" -- Columns (comma-separated) whose values will be merged [String]
		RemoveDuplicatesWhenMerging = false -- Remove duplicate values when merging columns [Boolean]
		IgnoreEmptyValuesWhenMerging = false -- Ignore empty column values when merging [Boolean]
		LineSeparator = ", " -- Line separator to use when merging consecutive consecutive rows [String]
		MaxRowsToMerge = -1 -- Maximum number of rows to merge [Int32]
		MaxCellSizeInBytes = 100000 -- Maximum size of merged cell in bytes [Int32]
END MERGE_CSV
---[TRANS2_CSV]---
BEGIN TRANS2_CSV
	UseMethod TransformRowsToColumn with -- **Transforms multiple table rows into new name/value columns**
		InputFile = "%{MERGE_CSV}" -- Input CSV file containing table data [String]
		ColumnNameForCaption = "Purge" -- Caption for new column type created after transformation [String]
		ColumnNameForValue = "Entity" -- Caption for new column value created after transformation [String]
		ExcludeColumnFilter = "" -- Columns to be excluded from output table (can include wild-cards and be separated by commas) [String]
		DefaultValue = "" -- Default value for cell if one does not exist [String]
END TRANS2_CSV
---[OPERPROC_CSV]---
BEGIN OPERPROC_CSV
	---Begin Main Query---
	Using UNIQE with
		DataSource = "${DATA_SOURCE}" -- UNIQE data source to query
		Authentication = "UNP" -- User Authentication Mode
		UserId = "${MAO_USERID}" -- User ID for authentication
	SELECT
	  OPERATION AS OperationTmp,
	  CU_FLAG,
	  STATE,
	  DOTPROCESS
	FROM
	  F_OPERATION
	WHERE
	  LATEST_VERSION = 'Y'
	  AND SRC_ERASE_DATE IS NULL 
END OPERPROC_CSV
---[THREEDIGIT_CSV]---
BEGIN THREEDIGIT_CSV
	---Begin Main Query---
	Using CSV with
	SELECT
		Operation,
		CU_FLAG,
		STATE,
		DOTPROCESS
	USING
		OperationTmp as Operation
	FROM
		%{OPERPROC_CSV}
END THREEDIGIT_CSV
---[JOINFINAL_CSV]---
BEGIN JOINFINAL_CSV
	UseMethod Join with -- **Do an outer join for two tables based on a matching column**
		InputFile1 = "%{TRANS_CSV}" -- Input CSV File #1 containing table data [String]
		InputFile2 = "%{TRANS2_CSV}" -- Input CSV File #2 containing table data [String]
		InputFile3 = "%{THREEDIGIT_CSV}" -- Input CSV File #3 containing table data (optional) [String]
		JoinColumn = "Operation" -- Column name(s) on which to join the two tables (more than one column can be supplied by using comma as a separator) [String]
		IgnoreDuplicate = true -- Flag to ignore duplicate items in the JoinColumn [Boolean]
		IgnoreCase = false -- Flag to ignore case in the JoinColumn [Boolean]
		OnlyShowNonMatchingRows = false -- Flag to only show non-matching orphan rows [Boolean]
		IncludeNonMatchingRows = true -- Flag to also include non-matching orphan rows (but with blank entries) [Boolean]
		MustIncludeOutputColumns = "" -- Name of columns (comma-separated) that must be included in output even if the join does not materialize [String]
		OrderBy = "" -- Name of column(s) to sort the resulting table by [String]
END JOINFINAL_CSV
---Begin Main Query---
Using CSV with
SELECT
	Enable,
	State as State,
	Operation,
	Process,
	LineSegment,
	Route,
	PurgeOnLoadPort,
	PurgeInStocker,
	Coefficient,
	OperShortDescription,
	[Associated Entities with Purge Enabled],
	[Associated Entities with Purge Disabled or Status Unknown],
	Comment
USING
	CASE to_string(DOTPROCESS) when 'GENTW' then '300mm' when 'GENPRD' then '300mm' else to_string(DOTPROCESS) end as ProcTmp,
	REPLACE_STR(ProcTmp, 'TW', '.0') as Process,
	CASE CU_FLAG when 'Required' then 'BE' else 'FE' end as LineSegment
FROM
	%{JOINFINAL_CSV}
WHERE
	Operation is not null
ORDER BY
	Operation

]]></QuerySQL>
</QueryConfig>